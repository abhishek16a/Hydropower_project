{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950fa369",
   "metadata": {},
   "source": [
    "# 02 – Data QA, Imputation, and Feature Engineering (Daily)\n",
    "\n",
    "**Goal:** Prepare model-ready daily features for GP (inflow & demand) and the BN module, aligned with your proposal.\n",
    "\n",
    "**Inputs:**\n",
    "- `master_kaligandaki_daily_withrain.csv` (2019–2023) with columns:\n",
    "  - `date`, `discharge_cms`, `gauge_m`, `rainfall_mm`,\n",
    "  - `peak_load_mw`, `avg_load_mw`, `energy_mwh`, `year`.\n",
    "\n",
    "**Outputs:**\n",
    "- `features_daily.csv` – cleaned & engineered features\n",
    "- Train/validation split markers (2019–2022 train, 2023 validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c81a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 0. Imports & Config ====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "MASTER_PATH = 'master_kaligandaki_daily_withrain.csv'  # change if needed\n",
    "OUT_FEATURES = 'features_daily.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80759c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 1. Load master data ====\n",
    "df = pd.read_csv(MASTER_PATH, parse_dates=['date']).sort_values('date').reset_index(drop=True)\n",
    "print(df.head())\n",
    "print('\\nDate range:', df['date'].min().date(), '→', df['date'].max().date(), '| rows=', len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 2. Quick QA – Missing counts and basic sanity ====\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "print('Missing values per column:\\n', missing)\n",
    "print('\\nBasic stats (selected):')\n",
    "print(df[['discharge_cms','gauge_m','rainfall_mm','peak_load_mw','avg_load_mw','energy_mwh']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49604f",
   "metadata": {},
   "source": [
    "### Imputation policy\n",
    "- Keep full daily calendar.\n",
    "- For **short gaps (≤3 days)** in `discharge_cms`, `gauge_m`, `peak_load_mw`, `avg_load_mw`, `energy_mwh`: use linear interpolation.\n",
    "- Leave long gaps as NaN and create **flag columns** (so models/BN can know about uncertainty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 3. Gap filling (linear) for short gaps only ====\n",
    "def linear_impute_short_gaps(s: pd.Series, max_gap: int = 3):\n",
    "    s = s.copy()\n",
    "    isna = s.isna()\n",
    "    if not isna.any():\n",
    "        return s, pd.Series(False, index=s.index)\n",
    "    blocks = []\n",
    "    start = None\n",
    "    for i, v in enumerate(isna):\n",
    "        if v and start is None:\n",
    "            start = i\n",
    "        if (not v or i == len(isna)-1) and start is not None:\n",
    "            end = i if not v else i\n",
    "            blocks.append((start, end))\n",
    "            start = None\n",
    "    imputed_flag = pd.Series(False, index=s.index)\n",
    "    for (a, b) in blocks:\n",
    "        length = b - a\n",
    "        if length <= max_gap:\n",
    "            s.iloc[a:b] = s.interpolate(limit=max_gap, limit_direction='both').iloc[a:b]\n",
    "            imputed_flag.iloc[a:b] = True\n",
    "    return s, imputed_flag\n",
    "\n",
    "cols_to_impute = ['discharge_cms','gauge_m','peak_load_mw','avg_load_mw','energy_mwh']\n",
    "for c in cols_to_impute:\n",
    "    df[c], df[f'{c}_imputed'] = linear_impute_short_gaps(df[c], max_gap=3)\n",
    "\n",
    "print('After imputation (short gaps):')\n",
    "print(df[cols_to_impute].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7288c75",
   "metadata": {},
   "source": [
    "### Outlier flagging (robust rule)\n",
    "- Compute rolling median (7 days) and MAD.\n",
    "- Flag points with |x − median| > 5 × MAD as potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d5a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 4. Outlier flags (robust) ====\n",
    "def mad_based_outlier_flags(x: pd.Series, window=7, k=5.0):\n",
    "    med = x.rolling(window, min_periods=1, center=True).median()\n",
    "    mad = (x - med).abs().rolling(window, min_periods=1, center=True).median()\n",
    "    return ((x - med).abs() > k * (mad + 1e-9)).astype(int)\n",
    "\n",
    "for c in ['discharge_cms','gauge_m','rainfall_mm','peak_load_mw','avg_load_mw','energy_mwh']:\n",
    "    df[f'{c}_outlier'] = mad_based_outlier_flags(df[c])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47019c2d",
   "metadata": {},
   "source": [
    "### Feature engineering (daily)\n",
    "- **Calendar:** day-of-week, month, monsoon flag (Jun–Sep)\n",
    "- **Lags:** 1, 2, 3, 7 days for hydrology & load\n",
    "- **Rolling:** 3, 7, 30-day means (and rainfall sums for 3 & 7)\n",
    "- **Targets:** next-day peak load and inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a376ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 5. Feature engineering ====\n",
    "df['dow'] = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n",
    "df['is_monsoon'] = df['month'].isin([6,7,8,9]).astype(int)\n",
    "\n",
    "lag_cols = ['discharge_cms','gauge_m','rainfall_mm','peak_load_mw','avg_load_mw','energy_mwh']\n",
    "for c in lag_cols:\n",
    "    for L in [1,2,3,7]:\n",
    "        df[f'{c}_lag{L}'] = df[c].shift(L)\n",
    "\n",
    "for c in ['discharge_cms','gauge_m','peak_load_mw','avg_load_mw']:\n",
    "    for W in [3,7,30]:\n",
    "        df[f'{c}_roll{W}'] = df[c].rolling(W, min_periods=1).mean()\n",
    "\n",
    "for W in [3,7]:\n",
    "    df[f'rainfall_sum{W}'] = df['rainfall_mm'].rolling(W, min_periods=1).sum()\n",
    "    df[f'rainfall_roll{W}'] = df['rainfall_mm'].rolling(W, min_periods=1).mean()\n",
    "\n",
    "df['y_demand_peak_next'] = df['peak_load_mw'].shift(-1)\n",
    "df['y_inflow_next'] = df['discharge_cms'].shift(-1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47817cca",
   "metadata": {},
   "source": [
    "### Train/Validation split\n",
    "- Train: 2019–2022\n",
    "- Validation: 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec961bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 6. Train/Validation mask ====\n",
    "df['set'] = np.where(df['date'] < '2023-01-01', 'train', 'valid')\n",
    "print(df['set'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 7. Save features ====\n",
    "df.to_csv(OUT_FEATURES, index=False)\n",
    "print('Saved features to:', OUT_FEATURES, '| rows=', len(df))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
