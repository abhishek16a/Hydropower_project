{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7a4d84",
   "metadata": {},
   "source": [
    "# 07_bayesian_network — Probabilistic Decision Support\n",
    "A compact **Bayesian Network (BN)** that fuses hydrology + text flags + GP forecast to infer **spill / shortfall / high‑load** risks and a suggested **decision**.\n",
    "\n",
    "**Inputs**\n",
    "- `master_with_topics.csv` (features + flags)\n",
    "- `predictions_test.csv` (from 05_modeling; provides `gpr_mean`, `gpr_std`)\n",
    "\n",
    "**Outputs**\n",
    "- `bn_inference.csv` with marginal posteriors per day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5d4ff",
   "metadata": {},
   "source": [
    "### Cell 1 — Imports & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BN library\n",
    "try:\n",
    "    from pgmpy.models import BayesianNetwork\n",
    "    from pgmpy.estimators import ParameterEstimator, MaximumLikelihoodEstimator, K2Score, HillClimbSearch, BayesianEstimator\n",
    "    from pgmpy.inference import VariableElimination\n",
    "except Exception as e:\n",
    "    print(\"If pgmpy is missing, run:  %pip install pgmpy\")\n",
    "\n",
    "FEATURES_PATH = \"master_with_topics.csv\"\n",
    "PRED_PATH     = \"predictions_test.csv\"\n",
    "\n",
    "print(Path(FEATURES_PATH).resolve())\n",
    "print(Path(PRED_PATH).resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddacd59",
   "metadata": {},
   "source": [
    "### Cell 2 — Load data, join forecasts, discretize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FEATURES_PATH, parse_dates=['date']).sort_values('date')\n",
    "pred = pd.read_csv(PRED_PATH, parse_dates=['date']) if Path(PRED_PATH).exists() else None\n",
    "\n",
    "# Detect typical columns\n",
    "def first_existing(cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "COL_LOAD = first_existing(['load_MW','peak_load_mw','avg_load_mw'])\n",
    "COL_RAIN = first_existing(['rainfall_mm'])\n",
    "COL_Q    = first_existing(['discharge_m3s','discharge_cms'])\n",
    "COL_RES  = first_existing(['reservoir_m','gauge_m'])\n",
    "\n",
    "if pred is not None and {'date','gpr_mean','gpr_std'}.issubset(pred.columns):\n",
    "    data = df.merge(pred[['date','gpr_mean','gpr_std']], on='date', how='left')\n",
    "else:\n",
    "    # fallback forecast: 7d MA + residual std\n",
    "    tmp = df[['date', COL_LOAD]].set_index('date').sort_index().asfreq('D')\n",
    "    gpr_mean = tmp[COL_LOAD].rolling(7, min_periods=3).mean()\n",
    "    gpr_std  = (tmp[COL_LOAD] - gpr_mean).rolling(30, min_periods=7).std().fillna(gpr_mean.std())\n",
    "    fb = pd.DataFrame({'date': gpr_mean.index, 'gpr_mean': gpr_mean.values, 'gpr_std': gpr_std.values})\n",
    "    data = df.merge(fb, on='date', how='left')\n",
    "\n",
    "data = data.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Capacity/min bound for derived binary nodes\n",
    "cap_mw = data[COL_LOAD].quantile(0.95) if COL_LOAD else data['gpr_mean'].quantile(0.95)\n",
    "min_mw = data[COL_LOAD].quantile(0.10) if COL_LOAD else data['gpr_mean'].quantile(0.10)\n",
    "\n",
    "# Derived probabilities from GP (using Normal tail)\n",
    "from scipy.stats import norm\n",
    "prob_highload  = 1 - norm.cdf((cap_mw - data['gpr_mean'])/data['gpr_std'].replace(0,np.nan))\n",
    "prob_shortfall = 1 - norm.cdf((data['gpr_mean'] - min_mw)/data['gpr_std'].replace(0,np.nan))\n",
    "\n",
    "# Discretize into categorical states {0,1}\n",
    "def binarize_prob(p, thr=0.5):\n",
    "    return (p >= thr).astype(int)\n",
    "\n",
    "def z_monthly(s):\n",
    "    g = data['date'].dt.month\n",
    "    return (s - s.groupby(g).transform('mean'))/s.groupby(g).transform('std')\n",
    "\n",
    "data['RainHigh']      = (z_monthly(data.get(COL_RAIN, pd.Series(0))) > 0.7).astype(int)\n",
    "data['DischargeHigh'] = (z_monthly(data.get(COL_Q, pd.Series(0))) > 0.7).astype(int)\n",
    "data['ReservoirHigh'] = (z_monthly(data.get(COL_RES, pd.Series(0))) > 0.7).astype(int)\n",
    "data['FloodFlag']     = data.get('flood_flag', 0).astype(int)\n",
    "data['WeatherFlag']   = data.get('weather_flag', 0).astype(int)\n",
    "data['MaintFlag']     = (data.get('maintenance_flag',0) + data.get('outage_flag',0)).clip(0,1).astype(int)\n",
    "\n",
    "data['GP_HighLoad']   = binarize_prob(prob_highload.fillna(0.0), 0.5)\n",
    "data['GP_Shortfall']  = binarize_prob(prob_shortfall.fillna(0.0), 0.5)\n",
    "\n",
    "# Targets we want to infer (latent risks as categories)\n",
    "data['RiskSpill']      = ((data['RainHigh']|data['DischargeHigh']|data['FloodFlag']|data['WeatherFlag'])>0).astype(int)\n",
    "data['RiskShortfall']  = data['GP_Shortfall']\n",
    "data['RiskHighLoad']   = data['GP_HighLoad']\n",
    "\n",
    "keep_cols = ['date','RainHigh','DischargeHigh','ReservoirHigh','FloodFlag','WeatherFlag','MaintFlag',\n",
    "             'GP_HighLoad','GP_Shortfall','RiskSpill','RiskShortfall','RiskHighLoad']\n",
    "bn_df = data[keep_cols].dropna().reset_index(drop=True)\n",
    "bn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d96d872",
   "metadata": {},
   "source": [
    "### Cell 3 — Define Bayesian Network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure (expert prior): \n",
    "# Rain/Discharge/Weather → RiskSpill\n",
    "# GP_* → corresponding risks\n",
    "# MaintFlag + RiskSpill/RiskHighLoad → Decision\n",
    "edges = [\n",
    "    ('RainHigh','RiskSpill'),\n",
    "    ('DischargeHigh','RiskSpill'),\n",
    "    ('WeatherFlag','RiskSpill'),\n",
    "    ('FloodFlag','RiskSpill'),\n",
    "    ('GP_Shortfall','RiskShortfall'),\n",
    "    ('GP_HighLoad','RiskHighLoad'),\n",
    "    ('MaintFlag','RiskHighLoad'),\n",
    "    ('MaintFlag','RiskShortfall'),\n",
    "]\n",
    "\n",
    "model = BayesianNetwork(edges)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491601ea",
   "metadata": {},
   "source": [
    "### Cell 4 — Learn CPDs (Maximum Likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e34779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All variables are binary 0/1 here\n",
    "# Fit CPDs via MLE (you can switch to BayesianEstimator with Dirichlet priors if data is sparse)\n",
    "model.fit(bn_df.drop(columns=['date']), estimator=MaximumLikelihoodEstimator)\n",
    "print(\"CPDs learned for nodes:\", [cpd.variable for cpd in model.get_cpds()])\n",
    "for cpd in model.get_cpds()[:4]:\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a50fac",
   "metadata": {},
   "source": [
    "### Cell 5 — Inference: compute daily marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999966b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = VariableElimination(model)\n",
    "\n",
    "# Evidence per-day: treat observed parents as evidence, infer posteriors for risks\n",
    "out_rows = []\n",
    "for _, r in bn_df.iterrows():\n",
    "    evidence = {\n",
    "        'RainHigh': int(r['RainHigh']),\n",
    "        'DischargeHigh': int(r['DischargeHigh']),\n",
    "        'WeatherFlag': int(r['WeatherFlag']),\n",
    "        'FloodFlag': int(r['FloodFlag']),\n",
    "        'GP_Shortfall': int(r['GP_Shortfall']),\n",
    "        'GP_HighLoad': int(r['GP_HighLoad']),\n",
    "        'MaintFlag': int(r['MaintFlag']),\n",
    "    }\n",
    "    q_spill = infer.query(['RiskSpill'], evidence=evidence, show_progress=False)\n",
    "    q_short = infer.query(['RiskShortfall'], evidence=evidence, show_progress=False)\n",
    "    q_high  = infer.query(['RiskHighLoad'], evidence=evidence, show_progress=False)\n",
    "\n",
    "    out_rows.append({\n",
    "        'date': r['date'],\n",
    "        'P(RiskSpill=1)': float(q_spill.values[1]),\n",
    "        'P(RiskShortfall=1)': float(q_short.values[1]),\n",
    "        'P(RiskHighLoad=1)': float(q_high.values[1]),\n",
    "    })\n",
    "\n",
    "bn_post = pd.DataFrame(out_rows)\n",
    "bn_post.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e16b23",
   "metadata": {},
   "source": [
    "### Cell 6 — Map BN posteriors → decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "THR_HIGH, THR_MED = 0.6, 0.35\n",
    "\n",
    "def decide(p_spill, p_short, p_high):\n",
    "    if p_spill >= THR_HIGH:\n",
    "        return 'Spill advisory'\n",
    "    if p_short >= THR_HIGH:\n",
    "        return 'Shortfall mitigation (imports/DR)'\n",
    "    if p_high >= THR_HIGH:\n",
    "        return 'Peak support readiness'\n",
    "    # medium levels\n",
    "    if p_spill >= THR_MED:\n",
    "        return 'Monitor spill readiness'\n",
    "    if p_short >= THR_MED:\n",
    "        return 'Monitor shortfall'\n",
    "    if p_high >= THR_MED:\n",
    "        return 'Monitor peak load'\n",
    "    return 'Normal ops'\n",
    "\n",
    "bn_post['decision'] = [decide(a,b,c) for a,b,c in bn_post[['P(RiskSpill=1)','P(RiskShortfall=1)','P(RiskHighLoad=1)']].values]\n",
    "bn_post.to_csv('bn_inference.csv', index=False)\n",
    "print(\"Saved bn_inference.csv | rows:\", len(bn_post))\n",
    "bn_post.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8f72e",
   "metadata": {},
   "source": [
    "### Cell 7 — Visualize posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(bn_post['date'], bn_post['P(RiskSpill=1)'], label='P(Spill)')\n",
    "plt.plot(bn_post['date'], bn_post['P(RiskShortfall=1)'], label='P(Shortfall)')\n",
    "plt.plot(bn_post['date'], bn_post['P(RiskHighLoad=1)'], label='P(HighLoad)')\n",
    "plt.axhline(0.6, color='k', ls='--', alpha=0.4); plt.axhline(0.35, color='k', ls=':', alpha=0.4)\n",
    "plt.legend(); plt.title('BN posterior risks'); plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
