{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f450c30",
   "metadata": {},
   "source": [
    "# 05_modeling — Baseline & Probabilistic Models\n",
    "Forecast daily **load (MW)** using hydrology + text features, aligned with proposal.\n",
    "\n",
    "**Models**\n",
    "- Baseline: **Persistence** (yesterday = today)\n",
    "- **Linear Regression** (tabular baseline)\n",
    "- **Gaussian Process Regression** (probabilistic; mean + uncertainty)\n",
    "\n",
    "**Data expected**: `master_with_topics.csv` from previous steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586c6c7",
   "metadata": {},
   "source": [
    "### Cell 1 — Imports & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806da2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "\n",
    "DATA_PATH = \"master_with_topics.csv\"\n",
    "DATE_COL  = \"date\"\n",
    "\n",
    "# Time-based split (adjust if needed)\n",
    "TRAIN_END = pd.Timestamp(\"2021-12-31\")\n",
    "VAL_END   = pd.Timestamp(\"2022-12-31\")  # test will be 2023\n",
    "\n",
    "print(\"Expecting:\", Path(DATA_PATH).resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05baf0dd",
   "metadata": {},
   "source": [
    "### Cell 2 — Load data & detect target/feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, parse_dates=[DATE_COL]).sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# Detect target column\n",
    "def first_existing(cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "TARGET = first_existing([\"load_MW\",\"peak_load_mw\",\"avg_load_mw\"])\n",
    "if TARGET is None:\n",
    "    raise ValueError(\"No load column found. Expected one of: load_MW, peak_load_mw, avg_load_mw\")\n",
    "\n",
    "# Candidate features: everything numeric except target\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in num_cols if c != TARGET]\n",
    "\n",
    "print(\"Rows:\", len(df), \"| Target:\", TARGET)\n",
    "print(\"Feature count:\", len(feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bae64d",
   "metadata": {},
   "source": [
    "### Cell 3 — Clean NaNs & time-based train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light imputation: forward-fill then back-fill for features only (not target)\n",
    "X_full = df[[DATE_COL] + feature_cols].copy().set_index(DATE_COL).sort_index()\n",
    "X_full = X_full.ffill().bfill()\n",
    "\n",
    "y_full = df[[DATE_COL, TARGET]].copy().set_index(DATE_COL).sort_index()\n",
    "# Keep target NaNs if any — we'll drop rows where y is NaN\n",
    "data = X_full.join(y_full, how=\"inner\").dropna(subset=[TARGET]).reset_index()\n",
    "\n",
    "# Split by dates\n",
    "train = data[data[DATE_COL] <= TRAIN_END].copy()\n",
    "val   = data[(data[DATE_COL] > TRAIN_END) & (data[DATE_COL] <= VAL_END)].copy()\n",
    "test  = data[data[DATE_COL] > VAL_END].copy()\n",
    "\n",
    "print(\"Split sizes:\", len(train), len(val), len(test))\n",
    "print(\"Date ranges:\")\n",
    "print(\"  Train:\", train[DATE_COL].min().date(), \"→\", train[DATE_COL].max().date())\n",
    "print(\"  Val  :\", val[DATE_COL].min().date() if len(val) else None, \"→\", val[DATE_COL].max().date() if len(val) else None)\n",
    "print(\"  Test :\", test[DATE_COL].min().date(), \"→\", test[DATE_COL].max().date())\n",
    "\n",
    "X_tr, y_tr = train[feature_cols], train[TARGET].values\n",
    "X_va, y_va = val[feature_cols],   val[TARGET].values\n",
    "X_te, y_te = test[feature_cols],  test[TARGET].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a434fab",
   "metadata": {},
   "source": [
    "### Cell 4 — Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((np.asarray(y_true) - np.asarray(y_pred))**2)))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return float(np.mean(np.abs(np.asarray(y_true) - np.asarray(y_pred))))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return float(np.mean(np.abs((y_true[mask]-y_pred[mask]) / y_true[mask]))*100)\n",
    "\n",
    "def report_metrics(split_name, y_true, y_pred):\n",
    "    print(f\"{split_name} → RMSE={rmse(y_true,y_pred):.2f} | MAE={mae(y_true,y_pred):.2f} | MAPE={mape(y_true,y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f082ee9f",
   "metadata": {},
   "source": [
    "### Cell 5 — Baseline model: Persistence (yesterday = today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a naive forecast by shifting the target by 1 day within each split\n",
    "def persistence_predict(df_split):\n",
    "    s = df_split[[DATE_COL, TARGET]].copy().set_index(DATE_COL).sort_index()\n",
    "    s['pred'] = s[TARGET].shift(1)\n",
    "    s = s.dropna()\n",
    "    return s.index.to_series(), s[TARGET].values, s['pred'].values\n",
    "\n",
    "# Train\n",
    "_, y_tr_pers_true, y_tr_pers_pred = persistence_predict(train)\n",
    "report_metrics(\"Train (Persistence)\", y_tr_pers_true, y_tr_pers_pred)\n",
    "\n",
    "# Val\n",
    "if len(val) > 1:\n",
    "    _, y_va_pers_true, y_va_pers_pred = persistence_predict(val)\n",
    "    report_metrics(\"Val   (Persistence)\", y_va_pers_true, y_va_pers_pred)\n",
    "\n",
    "# Test\n",
    "_, y_te_pers_true, y_te_pers_pred = persistence_predict(test)\n",
    "report_metrics(\"Test  (Persistence)\", y_te_pers_true, y_te_pers_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f3031",
   "metadata": {},
   "source": [
    "### Cell 6 — Linear Regression (with StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efeeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "lin.fit(X_tr, y_tr)\n",
    "\n",
    "pred_tr = lin.predict(X_tr)\n",
    "report_metrics(\"Train (Linear)\", y_tr, pred_tr)\n",
    "\n",
    "if len(val):\n",
    "    pred_va = lin.predict(X_va)\n",
    "    report_metrics(\"Val   (Linear)\", y_va, pred_va)\n",
    "\n",
    "pred_te = lin.predict(X_te)\n",
    "report_metrics(\"Test  (Linear)\", y_te, pred_te)\n",
    "\n",
    "# Quick plot on test\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(test[DATE_COL], y_te, label=\"Actual\")\n",
    "plt.plot(test[DATE_COL], pred_te, label=\"Linear pred\")\n",
    "plt.title(\"Linear Regression — Test\")\n",
    "plt.xlabel(\"date\"); plt.ylabel(TARGET)\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Coeff summary (top absolute weights)\n",
    "coefs = pd.Series(lin.named_steps[\"model\"].coef_, index=feature_cols).sort_values(key=np.abs, ascending=False)\n",
    "coefs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32171f95",
   "metadata": {},
   "source": [
    "### Cell 7 — Gaussian Process Regression (mean + uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel: C * RBF + White noise\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=np.ones(len(feature_cols)), length_scale_bounds=(1e-2, 1e3))          + WhiteKernel(noise_level=1.0, noise_level_bounds=(1e-5, 1e2))\n",
    "\n",
    "gpr = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"model\", GaussianProcessRegressor(kernel=kernel, normalize_y=True, random_state=42, n_restarts_optimizer=2))\n",
    "])\n",
    "\n",
    "# Fit on train (you may try train+val for final model)\n",
    "gpr.fit(X_tr, y_tr)\n",
    "\n",
    "# Predictions with std (→ 95% interval ≈ mean ± 1.96*std)\n",
    "def gpr_predict(pipe, X):\n",
    "    mean, std = pipe.named_steps[\"model\"].predict(pipe.named_steps[\"scaler\"].transform(X), return_std=True)\n",
    "    return mean, std\n",
    "\n",
    "m_tr, s_tr = gpr_predict(gpr, X_tr)\n",
    "report_metrics(\"Train (GPR)\", y_tr, m_tr)\n",
    "\n",
    "if len(val):\n",
    "    m_va, s_va = gpr_predict(gpr, X_va)\n",
    "    report_metrics(\"Val   (GPR)\", y_va, m_va)\n",
    "\n",
    "m_te, s_te = gpr_predict(gpr, X_te)\n",
    "report_metrics(\"Test  (GPR)\", y_te, m_te)\n",
    "\n",
    "# Plot: Test mean + 95% interval\n",
    "t = test[DATE_COL].values\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(test[DATE_COL], y_te, label=\"Actual\", linewidth=1)\n",
    "plt.plot(test[DATE_COL], m_te, label=\"GPR mean\", linewidth=1)\n",
    "upper = m_te + 1.96*s_te\n",
    "lower = m_te - 1.96*s_te\n",
    "plt.fill_between(test[DATE_COL], lower, upper, alpha=0.2, label=\"~95% PI\")\n",
    "plt.title(\"Gaussian Process — Test (mean ± 1.96·std)\")\n",
    "plt.xlabel(\"date\"); plt.ylabel(TARGET)\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Empirical coverage of 95% interval\n",
    "inside = ((y_te >= lower) & (y_te <= upper)).mean()\n",
    "print(f\"Test PI coverage (~95% target): {inside*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc31101",
   "metadata": {},
   "source": [
    "### Cell 8 — Save predictions for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51756f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_te = pd.DataFrame({\n",
    "    \"date\": test[DATE_COL].values,\n",
    "    \"y_true\": y_te,\n",
    "    \"lin_pred\": pred_te,\n",
    "    \"gpr_mean\": m_te,\n",
    "    \"gpr_std\": s_te,\n",
    "    \"gpr_pi_low\": m_te - 1.96*s_te,\n",
    "    \"gpr_pi_high\": m_te + 1.96*s_te,\n",
    "})\n",
    "out_te.to_csv(\"predictions_test.csv\", index=False)\n",
    "print(\"Saved predictions_test.csv | rows:\", len(out_te))\n",
    "out_te.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
